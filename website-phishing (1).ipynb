{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"5e7a6d6f-386b-4000-b82b-b1fe54348b79","_cell_guid":"118fae70-ca75-4764-8790-983d95af0f05","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:45:57.402125Z","iopub.execute_input":"2021-09-30T05:45:57.402476Z","iopub.status.idle":"2021-09-30T05:45:57.423417Z","shell.execute_reply.started":"2021-09-30T05:45:57.402359Z","shell.execute_reply":"2021-09-30T05:45:57.422356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading Data**\n\nThe features are extracted and store in the csv file. The working of this can be seen in the 'Phishing Website Detection_Feature Extraction.ipynb' file.\n\nThe reulted csv file is uploaded to this notebook and stored in the dataframe","metadata":{"_uuid":"983c717e-20ab-4421-a6d5-fb1cd52c434d","_cell_guid":"d930e1f8-883a-4bf8-9417-58deeb265bfc","trusted":true}},{"cell_type":"code","source":"#importing basic packages\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"c23ac7cb-b25e-44d6-b949-2c6ff2bf68cb","_cell_guid":"8d7c9820-740c-4e18-8c04-c598ba1b742e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:45:57.425136Z","iopub.execute_input":"2021-09-30T05:45:57.425374Z","iopub.status.idle":"2021-09-30T05:45:57.781142Z","shell.execute_reply.started":"2021-09-30T05:45:57.425337Z","shell.execute_reply":"2021-09-30T05:45:57.780190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading the data\ndata1 = pd.read_csv('/kaggle/input/phishing-detection/5.urldata.csv')\ndata1.head()","metadata":{"_uuid":"55c01952-6a06-4cfb-8a7d-b3fbc710a12a","_cell_guid":"3ae1a9b1-c3a6-4fc1-a833-0eaf81765de1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:45:57.782404Z","iopub.execute_input":"2021-09-30T05:45:57.782982Z","iopub.status.idle":"2021-09-30T05:45:57.824131Z","shell.execute_reply.started":"2021-09-30T05:45:57.782946Z","shell.execute_reply":"2021-09-30T05:45:57.823268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Familiarizing with Data**\nIn this step, few dataframe methods are used to look into the data and its features.","metadata":{"_uuid":"84bd62e5-1c79-4855-a31e-d77ff5819973","_cell_guid":"5728f024-36e9-48c5-8624-9347565997e5","trusted":true}},{"cell_type":"code","source":"#Checking the shape of the dataset\ndata1.shape","metadata":{"_uuid":"797bb4a2-c79a-4f38-b2bd-57eae6861b9d","_cell_guid":"aa8616be-e16c-478e-9522-ff28cf2d2ef0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:45:57.825953Z","iopub.execute_input":"2021-09-30T05:45:57.826258Z","iopub.status.idle":"2021-09-30T05:45:57.832398Z","shell.execute_reply.started":"2021-09-30T05:45:57.826231Z","shell.execute_reply":"2021-09-30T05:45:57.831503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking the columns we have","metadata":{"_uuid":"4e63fb3c-d5a9-4523-aadd-40ba9a57cd78","_cell_guid":"2f57ca77-6759-4f6c-9a1c-444572663d76","trusted":true}},{"cell_type":"code","source":"#Listing the features of the dataset\ndata1.columns","metadata":{"_uuid":"676ba3be-aac3-4780-aeb6-f0c5467f367d","_cell_guid":"7cc1c60a-b83f-431c-9d5d-afd005f422cd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:45:57.833750Z","iopub.execute_input":"2021-09-30T05:45:57.834012Z","iopub.status.idle":"2021-09-30T05:45:57.846542Z","shell.execute_reply.started":"2021-09-30T05:45:57.833976Z","shell.execute_reply":"2021-09-30T05:45:57.845824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Information about the dataset\ndata1.info()","metadata":{"_uuid":"cf273657-a6d8-43dd-9ea8-3680edc0e7ae","_cell_guid":"9c248d96-34a8-4bcc-ab97-cda3271b410e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:45:57.847751Z","iopub.execute_input":"2021-09-30T05:45:57.848204Z","iopub.status.idle":"2021-09-30T05:45:57.869221Z","shell.execute_reply.started":"2021-09-30T05:45:57.848172Z","shell.execute_reply":"2021-09-30T05:45:57.868021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualizing the data**\nFew plots and graphs are displayed to find how the data is distributed and the how features are related to each other.","metadata":{"_uuid":"4bdf3614-25d5-4b03-a1ab-fadb203fa951","_cell_guid":"4f91394b-69eb-4e2d-82ff-540d6dfb363a","trusted":true}},{"cell_type":"code","source":"#Plotting the data distribution\ndata1.hist(bins = 50,figsize = (15,15))\nplt.show()","metadata":{"_uuid":"8a1d746a-9e94-43e6-884e-737525c7fa8a","_cell_guid":"bc3b7d78-e41c-4cd3-914b-865bf15a3304","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:45:57.870600Z","iopub.execute_input":"2021-09-30T05:45:57.871199Z","iopub.status.idle":"2021-09-30T05:46:01.809035Z","shell.execute_reply.started":"2021-09-30T05:45:57.871154Z","shell.execute_reply":"2021-09-30T05:46:01.808186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Correlation heatmap\n\nplt.figure(figsize=(15,13))\n# sns.heatmap(data1.corr())\nsns.heatmap(data1.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm', linewidths=3, linecolor='black')\nplt.show()","metadata":{"_uuid":"a2a6b8a5-256b-4950-b708-a3518cd0810b","_cell_guid":"79a734e3-c619-4593-95e7-b197c4c42bf4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:01.810371Z","iopub.execute_input":"2021-09-30T05:46:01.810881Z","iopub.status.idle":"2021-09-30T05:46:03.514652Z","shell.execute_reply.started":"2021-09-30T05:46:01.810846Z","shell.execute_reply":"2021-09-30T05:46:03.513564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Preprocessing & EDA**\nHere, we clean the data by applying data preprocesssing techniques and transform the data to use it in the models.","metadata":{"_uuid":"fa4f6cba-8919-44bb-b0c9-24ade2816937","_cell_guid":"8285422f-8e0e-4e07-80d1-7da6e8245a8f","trusted":true}},{"cell_type":"code","source":"data1.describe()","metadata":{"_uuid":"6c236b09-d987-44a9-8602-837f9964b9e9","_cell_guid":"8700281b-933a-4f2a-b47a-5f94b8053a65","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:03.517700Z","iopub.execute_input":"2021-09-30T05:46:03.518332Z","iopub.status.idle":"2021-09-30T05:46:03.581007Z","shell.execute_reply.started":"2021-09-30T05:46:03.518269Z","shell.execute_reply":"2021-09-30T05:46:03.580161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above obtained result shows that the most of the data is made of 0's & 1's except 'Domain' & 'URL_Depth' columns. The Domain column doesnt have any significance to the machine learning model training. So dropping the 'Domain' column from the dataset.","metadata":{"_uuid":"2e9d4ed4-b6c3-468b-8923-0debf7892d09","_cell_guid":"7e5814d9-9850-4afa-b8b2-0de4919d0512","trusted":true}},{"cell_type":"code","source":"#Dropping the Domain column\ndata = data1.drop(['Domain'], axis = 1).copy()","metadata":{"_uuid":"e9ef41ce-228b-403b-b936-886653457317","_cell_guid":"46315e17-be74-488e-9b5e-03ab7ba491c0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:03.583929Z","iopub.execute_input":"2021-09-30T05:46:03.584177Z","iopub.status.idle":"2021-09-30T05:46:03.591038Z","shell.execute_reply.started":"2021-09-30T05:46:03.584149Z","shell.execute_reply":"2021-09-30T05:46:03.589960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This leaves us with 16 features & a target column. The 'URL_Depth' maximum value is 20. According to my understanding, there is no necessity to change this column.","metadata":{"_uuid":"c0db2521-c51c-428b-b643-f59c48053473","_cell_guid":"2a5128a6-8320-4fd1-b2a9-508c00a865c1","trusted":true}},{"cell_type":"code","source":"#checking the data for null or missing values\ndata.isnull().sum()","metadata":{"_uuid":"58b02702-70d4-4287-bf7e-4dc43b420b62","_cell_guid":"38f9dff3-5bbb-4c53-937a-8eba92588417","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:03.592479Z","iopub.execute_input":"2021-09-30T05:46:03.592722Z","iopub.status.idle":"2021-09-30T05:46:03.609289Z","shell.execute_reply.started":"2021-09-30T05:46:03.592695Z","shell.execute_reply":"2021-09-30T05:46:03.608382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the feature extraction file, the extracted features of legitmate & phishing url datasets are just concatenated without any shuffling. This resulted in top 5000 rows of legitimate url data & bottom 5000 of phishing url data.\n\nTo even out the distribution while splitting the data into training & testing sets, we need to shuffle it. This even evades the case of overfitting while model training.","metadata":{"_uuid":"d1a141c2-f7f0-4d91-99fc-8b75a362f015","_cell_guid":"998aa0f6-ea72-45fc-a11b-9c5d7716191e","trusted":true}},{"cell_type":"code","source":"# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\ndata = data.sample(frac=1).reset_index(drop=True)\ndata.head()","metadata":{"_uuid":"227be232-527b-4d84-8b72-9c4d7d643445","_cell_guid":"548313e7-a7b0-4c7f-90e2-320df036a5e2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:03.610541Z","iopub.execute_input":"2021-09-30T05:46:03.610818Z","iopub.status.idle":"2021-09-30T05:46:03.631492Z","shell.execute_reply.started":"2021-09-30T05:46:03.610791Z","shell.execute_reply":"2021-09-30T05:46:03.630561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above execution, it is clear that the data doesnot have any missing values.\n\nBy this, the data is throughly preprocessed & is ready for training.","metadata":{"_uuid":"f1d83219-3c1b-44d8-849a-76c8d2953ea7","_cell_guid":"a7526a87-b5b5-4178-b09d-549546b51d65","trusted":true}},{"cell_type":"markdown","source":"Splitting the Data","metadata":{"_uuid":"7d2ac62b-3f48-4135-9eb5-c1d229b8bf08","_cell_guid":"be2110fa-64c3-4b7a-8cbe-dd85d1ca4b68","trusted":true}},{"cell_type":"code","source":"# Sepratating & assigning features and target columns to X & y\ny = data['Label']\nX = data.drop('Label',axis=1)\nX.shape, y.shape","metadata":{"_uuid":"3c41a201-78d9-4e6c-ab2b-cafbc8b58939","_cell_guid":"78008f3d-69dd-4125-b428-a32f127721b2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:03.632839Z","iopub.execute_input":"2021-09-30T05:46:03.633231Z","iopub.status.idle":"2021-09-30T05:46:03.642283Z","shell.execute_reply.started":"2021-09-30T05:46:03.633188Z","shell.execute_reply":"2021-09-30T05:46:03.641611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into train and test sets: 80-20 split\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size = 0.2, random_state = 12)\nX_train.shape, X_test.shape","metadata":{"_uuid":"3d4c4a31-d2dd-4d57-8d57-58303efde4a5","_cell_guid":"a337cde4-7289-413a-a730-56bc579fa5b3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:03.643453Z","iopub.execute_input":"2021-09-30T05:46:03.644283Z","iopub.status.idle":"2021-09-30T05:46:03.714374Z","shell.execute_reply.started":"2021-09-30T05:46:03.644246Z","shell.execute_reply":"2021-09-30T05:46:03.713520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MACHINE LEARNING ALGORITHM\nThis is a supervised machine learning task. There are two major types of supervised machine learning problems, called classification and regression. This data set comes under classification problem, as the input URL is classified as phishing (1) or legitimate (0).\n* Decision Tree\n* Random Forest\n* Multilayer Perceptrons\n* XGBoost\n* Support Vector Machines","metadata":{"_uuid":"f893d3e7-c96f-4c12-aff1-8e3f105cb341","_cell_guid":"13995f87-527c-45e3-9e0e-62ec8c126e60","trusted":true}},{"cell_type":"code","source":"#importing packages\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"360cba8e-e414-4c58-88e7-57fbb3f815ce","_cell_guid":"417830b3-6b3e-4049-9d8a-b67d1a0cf015","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:03.715751Z","iopub.execute_input":"2021-09-30T05:46:03.715987Z","iopub.status.idle":"2021-09-30T05:46:03.719831Z","shell.execute_reply.started":"2021-09-30T05:46:03.715961Z","shell.execute_reply":"2021-09-30T05:46:03.718986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating holders to store the model performance results\nML_Model = []\nacc_train = []\nacc_test = []\n\n#function to call for storing the results\ndef storeResults(model, a,b):\n  ML_Model.append(model)\n  acc_train.append(round(a, 3))\n  acc_test.append(round(b, 3))","metadata":{"_uuid":"c437180c-9b9f-4c38-87f6-c4de639431b8","_cell_guid":"d4815dd4-5971-402c-984e-7911fb5aac23","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:03.721024Z","iopub.execute_input":"2021-09-30T05:46:03.721334Z","iopub.status.idle":"2021-09-30T05:46:03.733556Z","shell.execute_reply.started":"2021-09-30T05:46:03.721307Z","shell.execute_reply":"2021-09-30T05:46:03.732594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Decision Tree Classifier\nDecision trees are widely used models for classification and regression tasks. Essentially, they learn a hierarchy of if/else questions, leading to a decision. Learning a decision tree means learning the sequence of if/else questions that gets us to the true answer most quickly.\n\nIn the machine learning setting, these questions are called tests (not to be confused with the test set, which is the data we use to test to see how generalizable our model is). To build a tree, the algorithm searches over all possible tests and finds the one that is most informative about the target variable.","metadata":{"_uuid":"72b64f6d-0ca2-4e46-a870-b53cfcd21d74","_cell_guid":"e8d1a52a-7c05-4a39-a752-fb1b9f80f1d4","trusted":true}},{"cell_type":"code","source":"# Decision Tree model \nfrom sklearn.tree import DecisionTreeClassifier\n\n# instantiate the model \ntree = DecisionTreeClassifier(max_depth = 5)\n# fit the model \ntree.fit(X_train, y_train)","metadata":{"_uuid":"61f1337c-0404-4c85-be9d-aec2bfe0a542","_cell_guid":"d7435421-45bc-494f-9449-739ec5129953","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:03.734729Z","iopub.execute_input":"2021-09-30T05:46:03.734952Z","iopub.status.idle":"2021-09-30T05:46:03.797984Z","shell.execute_reply.started":"2021-09-30T05:46:03.734927Z","shell.execute_reply":"2021-09-30T05:46:03.797120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_tree = tree.predict(X_test)\ny_train_tree = tree.predict(X_train)","metadata":{"_uuid":"75efe9da-0c34-4e0e-acd4-f31d394ece22","_cell_guid":"66cb2ff9-0b6d-43b3-8f8a-d125461d5401","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:03.799159Z","iopub.execute_input":"2021-09-30T05:46:03.799381Z","iopub.status.idle":"2021-09-30T05:46:03.809468Z","shell.execute_reply.started":"2021-09-30T05:46:03.799356Z","shell.execute_reply":"2021-09-30T05:46:03.808504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performance Evaluation:","metadata":{"_uuid":"2645a8fb-ed31-4e1a-9129-56b06929c3cb","_cell_guid":"57d326f2-5ebd-40a3-91b4-4eacf4db3d78","trusted":true}},{"cell_type":"code","source":"#computing the accuracy of the model performance\nacc_train_tree = accuracy_score(y_train,y_train_tree)\nacc_test_tree = accuracy_score(y_test,y_test_tree)\n\nprint(\"Decision Tree: Accuracy on training Data: {:.3f}\".format(acc_train_tree))\nprint(\"Decision Tree: Accuracy on test Data: {:.3f}\".format(acc_test_tree))","metadata":{"_uuid":"195356de-cd8b-44f3-9b31-26f8fbb55763","_cell_guid":"6ec9ec7c-f1c5-489f-99e8-53f0cb72ed21","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:03.811020Z","iopub.execute_input":"2021-09-30T05:46:03.811668Z","iopub.status.idle":"2021-09-30T05:46:03.821793Z","shell.execute_reply.started":"2021-09-30T05:46:03.811629Z","shell.execute_reply":"2021-09-30T05:46:03.821120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the feature improtance in the model\nplt.figure(figsize=(9,7))\nn_features = X_train.shape[1]\nplt.barh(range(n_features), tree.feature_importances_, align='center')\nplt.yticks(np.arange(n_features), X_train.columns)\nplt.xlabel(\"Feature importance\")\nplt.ylabel(\"Feature\")\nplt.show()","metadata":{"_uuid":"dc144335-9b0d-42cc-90a5-b6be93a2cc1e","_cell_guid":"2f756ecc-b1ae-4710-b772-98a952dc7d47","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:03.822997Z","iopub.execute_input":"2021-09-30T05:46:03.823579Z","iopub.status.idle":"2021-09-30T05:46:04.107711Z","shell.execute_reply.started":"2021-09-30T05:46:03.823536Z","shell.execute_reply":"2021-09-30T05:46:04.106736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Storing the results:","metadata":{"_uuid":"714cf0aa-d62d-450d-a84c-91c1ece0b8c1","_cell_guid":"54343c86-b842-447c-8c0c-d9b323fdd5a4","trusted":true}},{"cell_type":"code","source":"#storing the results. The below mentioned order of parameter passing is important.\n#Caution: Execute only once to avoid duplications.\nstoreResults('Decision Tree', acc_train_tree, acc_test_tree)","metadata":{"_uuid":"e809e3cf-4eb7-41a6-87df-818816f57f24","_cell_guid":"e229a0c6-c211-4a88-904a-a798d4a98f88","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:04.109246Z","iopub.execute_input":"2021-09-30T05:46:04.109589Z","iopub.status.idle":"2021-09-30T05:46:04.115213Z","shell.execute_reply.started":"2021-09-30T05:46:04.109548Z","shell.execute_reply":"2021-09-30T05:46:04.113937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random Forest Classifier\nRandom forest algorithm is one of the most powerful algorithms in machine learning technology and it is based on concept of decision tree algorithm. Random forest algorithm creates the forest with number of decision trees. High number of tree gives high detection accuracy.\n\nIf we build many trees, all of which work well and overfit in different ways, we can reduce the amount of overfitting by averaging their results. To build a random forest model, you need to decide on the number of trees to build (the n_estimators parameter of RandomForestRegressor or RandomForestClassifier). They are very powerful, often work well without heavy tuning of the parameters, and don’t require scaling of the data.","metadata":{"_uuid":"cc2dcb8c-a052-4f6f-9312-e8c42cf607a9","_cell_guid":"3e932669-5b9c-47c6-b217-4ab9a30d969e","trusted":true}},{"cell_type":"code","source":"# Random Forest model\nfrom sklearn.ensemble import RandomForestClassifier\n\n# instantiate the model\nforest = RandomForestClassifier(max_depth=5)\n\n# fit the model \nforest.fit(X_train, y_train)","metadata":{"_uuid":"2748fd45-c14b-4542-a77f-1ed8ddcdaef3","_cell_guid":"8cb6ac3c-83b7-4ee1-8f04-e703f0acf763","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:04.116739Z","iopub.execute_input":"2021-09-30T05:46:04.117626Z","iopub.status.idle":"2021-09-30T05:46:04.479272Z","shell.execute_reply.started":"2021-09-30T05:46:04.117580Z","shell.execute_reply":"2021-09-30T05:46:04.478452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_forest = forest.predict(X_test)\ny_train_forest = forest.predict(X_train)","metadata":{"_uuid":"3c212778-50a2-44c6-ac97-4fea15693942","_cell_guid":"cf404054-57f2-4bfc-8125-b16c380f45c6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:04.480466Z","iopub.execute_input":"2021-09-30T05:46:04.480699Z","iopub.status.idle":"2021-09-30T05:46:04.564378Z","shell.execute_reply.started":"2021-09-30T05:46:04.480674Z","shell.execute_reply":"2021-09-30T05:46:04.563781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nPerformance Evaluation:","metadata":{"_uuid":"c4ee7cc5-0d5d-4210-9f4f-b1455c0753df","_cell_guid":"9080600a-8062-4b25-97e4-ddd886473370","trusted":true}},{"cell_type":"code","source":"#computing the accuracy of the model performance\nacc_train_forest = accuracy_score(y_train,y_train_forest)\nacc_test_forest = accuracy_score(y_test,y_test_forest)\n\nprint(\"Random forest: Accuracy on training Data: {:.3f}\".format(acc_train_forest))\nprint(\"Random forest: Accuracy on test Data: {:.3f}\".format(acc_test_forest))","metadata":{"_uuid":"d52f2615-b224-4c80-af28-1b66909f0cdd","_cell_guid":"648b4729-84a6-43ef-b8d1-2b46b76cb9e4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:04.565669Z","iopub.execute_input":"2021-09-30T05:46:04.566113Z","iopub.status.idle":"2021-09-30T05:46:04.572638Z","shell.execute_reply.started":"2021-09-30T05:46:04.566083Z","shell.execute_reply":"2021-09-30T05:46:04.571590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the feature improtance in the model\nplt.figure(figsize=(9,7))\nn_features = X_train.shape[1]\nplt.barh(range(n_features), forest.feature_importances_, align='center')\nplt.yticks(np.arange(n_features), X_train.columns)\nplt.xlabel(\"Feature importance\")\nplt.ylabel(\"Feature\")\nplt.show()","metadata":{"_uuid":"263b154e-8638-4f5d-92ba-9c3cdb2315e6","_cell_guid":"51f973b5-e90e-47e7-b293-75238e975136","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:04.573964Z","iopub.execute_input":"2021-09-30T05:46:04.574170Z","iopub.status.idle":"2021-09-30T05:46:04.858809Z","shell.execute_reply.started":"2021-09-30T05:46:04.574145Z","shell.execute_reply":"2021-09-30T05:46:04.857874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Storing the results:","metadata":{"_uuid":"e1e1be77-5856-41f4-8f1a-8147b97bce77","_cell_guid":"3b5d5fac-0497-4521-b4a6-bd8ad02f8766","trusted":true}},{"cell_type":"code","source":"#storing the results. The below mentioned order of parameter passing is important.\n#Caution: Execute only once to avoid duplications.\nstoreResults('Random Forest', acc_train_forest, acc_test_forest)","metadata":{"_uuid":"6d91f5a6-2aad-4e29-8260-57a412021a69","_cell_guid":"c6d90427-5ce9-4458-bbcb-cfdf276b3be9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:04.860211Z","iopub.execute_input":"2021-09-30T05:46:04.860548Z","iopub.status.idle":"2021-09-30T05:46:04.865034Z","shell.execute_reply.started":"2021-09-30T05:46:04.860503Z","shell.execute_reply":"2021-09-30T05:46:04.863992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Multilayer Perceptrons (MLPs): Deep Learning\nMultilayer perceptrons (MLPs) are also known as (vanilla) feed-forward neural networks, or sometimes just neural networks. Multilayer perceptrons can be applied for both classification and regression problems.It is a supplement of feed forward neural network. It consists of three types of layers: the input layer, output layer and hidden layer as shown below.\n\n![image.png](attachment:afe09f9d-73bd-4581-9992-7d316fb96bd5.png)","metadata":{"_uuid":"030c5888-aa6d-4f1f-bddc-6d53e4067424","_cell_guid":"c1a129f9-91c8-4242-aa42-371aa29b1f30","trusted":true}},{"cell_type":"code","source":"# Multilayer Perceptrons model\nfrom sklearn.neural_network import MLPClassifier\n\n# instantiate the model\nmlp = MLPClassifier(alpha=0.001, hidden_layer_sizes=([100,100,100]))\n\n# fit the model \nmlp.fit(X_train, y_train)","metadata":{"_uuid":"7d92a75e-2eab-45e4-83c4-ccbdab0440fd","_cell_guid":"da7d2fd0-5d9e-42cd-8b1c-0a0119b8434f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:04.866200Z","iopub.execute_input":"2021-09-30T05:46:04.866464Z","iopub.status.idle":"2021-09-30T05:46:19.385415Z","shell.execute_reply.started":"2021-09-30T05:46:04.866424Z","shell.execute_reply":"2021-09-30T05:46:19.384603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_mlp = mlp.predict(X_test)\ny_train_mlp = mlp.predict(X_train)","metadata":{"_uuid":"664fd3d4-883e-4a31-8203-c8fa82d1fa64","_cell_guid":"e6927c53-644e-461d-b88a-aff9e299069a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:19.390699Z","iopub.execute_input":"2021-09-30T05:46:19.391541Z","iopub.status.idle":"2021-09-30T05:46:19.457115Z","shell.execute_reply.started":"2021-09-30T05:46:19.391498Z","shell.execute_reply":"2021-09-30T05:46:19.456115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performance Evaluation:","metadata":{"_uuid":"5971c7a8-a394-437e-a41a-fbfe90a32414","_cell_guid":"468d1376-8072-490c-8f8c-39f8c55f1bda","trusted":true}},{"cell_type":"code","source":"#computing the accuracy of the model performance\nacc_train_mlp = accuracy_score(y_train,y_train_mlp)\nacc_test_mlp = accuracy_score(y_test,y_test_mlp)\n\nprint(\"Multilayer Perceptrons: Accuracy on training Data: {:.3f}\".format(acc_train_mlp))\nprint(\"Multilayer Perceptrons: Accuracy on test Data: {:.3f}\".format(acc_test_mlp))","metadata":{"_uuid":"8fd75617-ee5e-4a48-b4ea-df38e46243a0","_cell_guid":"20a1dc33-7e26-416e-a53f-198f91fc132f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:19.458682Z","iopub.execute_input":"2021-09-30T05:46:19.459163Z","iopub.status.idle":"2021-09-30T05:46:19.470026Z","shell.execute_reply.started":"2021-09-30T05:46:19.459123Z","shell.execute_reply":"2021-09-30T05:46:19.468784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Storing results:","metadata":{"_uuid":"9aa3e3cd-eebb-4d97-804d-97976ba4a4cd","_cell_guid":"e713782d-776d-4b60-84f5-b2e5fbc2263b","trusted":true}},{"cell_type":"code","source":"#storing the results. The below mentioned order of parameter passing is important.\n#Caution: Execute only once to avoid duplications.\nstoreResults('Multilayer Perceptrons', acc_train_mlp, acc_test_mlp)","metadata":{"_uuid":"cecc782c-178b-4f8f-8c7a-ec6f9c5a07bb","_cell_guid":"ed05dd2e-9609-4fce-a6b8-2454e10d15d2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:19.472049Z","iopub.execute_input":"2021-09-30T05:46:19.472731Z","iopub.status.idle":"2021-09-30T05:46:19.481221Z","shell.execute_reply.started":"2021-09-30T05:46:19.472689Z","shell.execute_reply":"2021-09-30T05:46:19.480356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"XGBoost Classifier\nXGBoost stands for eXtreme Gradient Boosting. XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable.Regardless of the type of prediction task at hand; regression or classification. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.\nThe two reasons to use XGBoost are also the two goals of the project:\n•\tExecution Speed.\n•\tModel Performance.","metadata":{"_uuid":"75d6eb50-5029-4978-9001-1d488a916a0a","_cell_guid":"29af08d8-04c9-461f-bed3-5eea3ccfd5e8","trusted":true}},{"cell_type":"code","source":"#XGBoost Classification model\nfrom xgboost import XGBClassifier\n\n# instantiate the model\nxgb = XGBClassifier(learning_rate=0.4,max_depth=7, use_label_encoder=False)\n#fit the model\nxgb.fit(X_train, y_train)","metadata":{"_uuid":"1db6c6da-5ead-4fce-ad68-967afb8832ec","_cell_guid":"0f619b6b-3d82-4ccb-92d2-eea695ab3aa0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:19.482875Z","iopub.execute_input":"2021-09-30T05:46:19.483476Z","iopub.status.idle":"2021-09-30T05:46:19.986868Z","shell.execute_reply.started":"2021-09-30T05:46:19.483411Z","shell.execute_reply":"2021-09-30T05:46:19.985777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_xgb = xgb.predict(X_test)\ny_train_xgb = xgb.predict(X_train)","metadata":{"_uuid":"88569958-66d6-45f5-aef5-1b5610623314","_cell_guid":"d10f6cdc-6ed2-4b4b-baf4-496d4d5df747","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:19.988349Z","iopub.execute_input":"2021-09-30T05:46:19.988870Z","iopub.status.idle":"2021-09-30T05:46:20.012974Z","shell.execute_reply.started":"2021-09-30T05:46:19.988827Z","shell.execute_reply":"2021-09-30T05:46:20.012284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performance evaluation:","metadata":{"_uuid":"8a69c8dc-80da-431f-b9de-e87879371f53","_cell_guid":"ee9682e8-8165-4163-9d01-ce0461688ee7","trusted":true}},{"cell_type":"code","source":"#computing the accuracy of the model performance\nacc_train_xgb = accuracy_score(y_train,y_train_xgb)\nacc_test_xgb = accuracy_score(y_test,y_test_xgb)\n\nprint(\"XGBoost: Accuracy on training Data: {:.3f}\".format(acc_train_xgb))\nprint(\"XGBoost : Accuracy on test Data: {:.3f}\".format(acc_test_xgb))","metadata":{"_uuid":"bf8d215e-c880-4066-8f38-288ade21356d","_cell_guid":"a1574d95-48e5-42ea-ae43-82ba718512d4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:20.014332Z","iopub.execute_input":"2021-09-30T05:46:20.014850Z","iopub.status.idle":"2021-09-30T05:46:20.025750Z","shell.execute_reply.started":"2021-09-30T05:46:20.014807Z","shell.execute_reply":"2021-09-30T05:46:20.024062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Storing results:","metadata":{"_uuid":"ff0ec65a-87d1-45f2-afaa-d07fc42ef262","_cell_guid":"7f549775-f42c-4305-a1ac-084c8ca797ec","trusted":true}},{"cell_type":"code","source":"#storing the results. The below mentioned order of parameter passing is important.\n#Caution: Execute only once to avoid duplications.\nstoreResults('XGBoost', acc_train_xgb, acc_test_xgb)","metadata":{"_uuid":"a76193db-08aa-466e-b1d5-af5c2163321d","_cell_guid":"c9a085a6-3b3c-42a3-92ed-b1d9c20060e7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:20.027873Z","iopub.execute_input":"2021-09-30T05:46:20.028423Z","iopub.status.idle":"2021-09-30T05:46:20.032900Z","shell.execute_reply.started":"2021-09-30T05:46:20.028388Z","shell.execute_reply":"2021-09-30T05:46:20.031955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Support Vector Machines\nIn machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier","metadata":{"_uuid":"e53b9f80-7d2f-4e13-a498-486883e3ac9d","_cell_guid":"ddd6ea69-30e3-4243-adf2-1c276fd1b3a9","trusted":true}},{"cell_type":"code","source":"#Support vector machine model\nfrom sklearn.svm import SVC\n\n# instantiate the model\nsvm = SVC(kernel='linear', C=1.0, random_state=12)\n#fit the model\nsvm.fit(X_train, y_train)","metadata":{"_uuid":"ed0c6c0a-2878-479a-bfda-b9c0d9d97206","_cell_guid":"8e910a2c-35df-421a-92fb-dcf5cbf40c65","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:20.033988Z","iopub.execute_input":"2021-09-30T05:46:20.034523Z","iopub.status.idle":"2021-09-30T05:46:21.328948Z","shell.execute_reply.started":"2021-09-30T05:46:20.034493Z","shell.execute_reply":"2021-09-30T05:46:21.328401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the target value from the model for the samples\ny_test_svm = svm.predict(X_test)\ny_train_svm = svm.predict(X_train)","metadata":{"_uuid":"f34235fd-9123-4ed9-a5b2-cbef27c70bfc","_cell_guid":"e1534658-f411-4c05-b67d-75e875ee8d91","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:21.329954Z","iopub.execute_input":"2021-09-30T05:46:21.330787Z","iopub.status.idle":"2021-09-30T05:46:21.880717Z","shell.execute_reply.started":"2021-09-30T05:46:21.330753Z","shell.execute_reply":"2021-09-30T05:46:21.880106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performance Evaluation:","metadata":{"_uuid":"d334df04-3006-4ec4-91d8-cd15b73c2f2f","_cell_guid":"6ba2d0ad-6964-46c1-baaa-83f7fa37c681","trusted":true}},{"cell_type":"code","source":"#computing the accuracy of the model performance\nacc_train_svm = accuracy_score(y_train,y_train_svm)\nacc_test_svm = accuracy_score(y_test,y_test_svm)\n\nprint(\"SVM: Accuracy on training Data: {:.3f}\".format(acc_train_svm))\nprint(\"SVM : Accuracy on test Data: {:.3f}\".format(acc_test_svm))","metadata":{"_uuid":"8f5eb53f-7a6b-4cb7-adb2-92dc9fe2e255","_cell_guid":"703f9fdc-9359-4122-a2ea-26b1fcfec7e4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:21.881718Z","iopub.execute_input":"2021-09-30T05:46:21.882349Z","iopub.status.idle":"2021-09-30T05:46:21.890919Z","shell.execute_reply.started":"2021-09-30T05:46:21.882311Z","shell.execute_reply":"2021-09-30T05:46:21.889936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#storing the results. The below mentioned order of parameter passing is important.\n#Caution: Execute only once to avoid duplications.\nstoreResults('SVM', acc_train_svm, acc_test_svm)","metadata":{"_uuid":"bbf9d442-ffa4-4414-b072-fb61cf108bd2","_cell_guid":"e330dea3-ee92-4101-a173-beed5e9717c8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:21.892247Z","iopub.execute_input":"2021-09-30T05:46:21.892574Z","iopub.status.idle":"2021-09-30T05:46:21.899401Z","shell.execute_reply.started":"2021-09-30T05:46:21.892484Z","shell.execute_reply":"2021-09-30T05:46:21.898382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comparision of Models¶\nTo compare the models performance, a dataframe is created. The columns of this dataframe are the lists created to store the results of the model.","metadata":{"_uuid":"eef19606-4618-44ca-ae31-a19e1cf6ad77","_cell_guid":"29838d49-757e-4b04-9104-81414a4158a5","trusted":true}},{"cell_type":"code","source":"#creating dataframe\nresults = pd.DataFrame({ 'ML Model': ML_Model,    \n    'Train Accuracy': acc_train,\n    'Test Accuracy': acc_test})\nresults","metadata":{"_uuid":"8f6307d0-b00d-44f0-9129-755e55689ac2","_cell_guid":"dafc0d24-d361-4655-a1c7-185729814813","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:21.900698Z","iopub.execute_input":"2021-09-30T05:46:21.900945Z","iopub.status.idle":"2021-09-30T05:46:21.922734Z","shell.execute_reply.started":"2021-09-30T05:46:21.900918Z","shell.execute_reply":"2021-09-30T05:46:21.921885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sorting the datafram on accuracy\nresults.sort_values(by=['Test Accuracy', 'Train Accuracy'], ascending=False)","metadata":{"_uuid":"17772ef5-ac49-4391-bd08-7abbc14f6522","_cell_guid":"37d9b9a2-6336-4e27-9031-853e0b60876a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:21.924121Z","iopub.execute_input":"2021-09-30T05:46:21.924360Z","iopub.status.idle":"2021-09-30T05:46:21.944328Z","shell.execute_reply.started":"2021-09-30T05:46:21.924330Z","shell.execute_reply":"2021-09-30T05:46:21.943485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the above comparision, it is clear that the XGBoost Classifier works well with this dataset.\n\nSo, saving the model for future use.","metadata":{"_uuid":"c81a0a3c-f4be-44a7-ab7c-0ab8ff586d6a","_cell_guid":"24d18cb7-6769-4bd6-967a-02b01f9c7c99","trusted":true}},{"cell_type":"code","source":"# save XGBoost model to file\nimport pickle\npickle.dump(xgb, open(\"XGBoostClassifier.pickle.dat\", \"wb\"))","metadata":{"_uuid":"f5bbc124-4d49-472c-a404-ed163f56a339","_cell_guid":"9a656dbc-fb77-49b6-84ac-9b594f4c1d62","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:21.945781Z","iopub.execute_input":"2021-09-30T05:46:21.946031Z","iopub.status.idle":"2021-09-30T05:46:21.964450Z","shell.execute_reply.started":"2021-09-30T05:46:21.945995Z","shell.execute_reply":"2021-09-30T05:46:21.963593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Testing the saved model:","metadata":{"_uuid":"1e28de75-da70-4f6b-a0bc-d3e3b0e1c59f","_cell_guid":"6e9647a4-7f41-4f63-9cd8-30b21ca816f0","trusted":true}},{"cell_type":"code","source":"# load model from file\nloaded_model = pickle.load(open(\"XGBoostClassifier.pickle.dat\", \"rb\"))\nloaded_model","metadata":{"_uuid":"b763dde1-ca61-4b84-b3d8-8f70c581e904","_cell_guid":"c38a22f4-8e15-4336-afad-53ab1f4b1a24","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-30T05:46:21.965921Z","iopub.execute_input":"2021-09-30T05:46:21.966408Z","iopub.status.idle":"2021-09-30T05:46:21.993109Z","shell.execute_reply.started":"2021-09-30T05:46:21.966377Z","shell.execute_reply":"2021-09-30T05:46:21.992251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" References\nhttps://blog.keras.io/building-autoencoders-in-keras.html\nhttps://en.wikipedia.org/wiki/Autoencoder\nhttps://mc.ai/a-beginners-guide-to-build-stacked-autoencoder-and-tying-weights-with-it/\nhttps://github.com/shreyagopal/t81_558_deep_learning/blob/master/t81_558_class_14_03_anomaly.ipynb\nhttps://machinelearningmastery.com/save-gradient-boosting-models-xgboost-python/","metadata":{"_uuid":"fc36292d-f237-457d-90ae-4672ecd3630f","_cell_guid":"7ec8eeac-bff7-4bc7-a6dc-3d93cf8875b7","trusted":true}}]}